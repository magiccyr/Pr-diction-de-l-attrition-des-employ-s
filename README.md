# ğŸ“Œ Projet IA â€” HumanForYou

- Analyse et prÃ©diction du turnover des employÃ©s

# ğŸ‘¥ Groupe 1

- Romain HEMART

- Cyr-Manuel DJOKI

- Antoine TAFFOUREAU

- Alban GODIER

ğŸ“… 19/12/2024

# ğŸ¯ Objectif du projet

Lâ€™entreprise pharmaceutique HumanForYou, basÃ©e en Inde, fait face Ã  un turnover Ã©levÃ©. Le salariÃ© type reste environ 500 jours, ce qui entraÃ®ne :

- des coÃ»ts de recrutement importants,

- une perte de productivitÃ©,

- un manque de stabilitÃ© pour lâ€™entreprise.

Lâ€™objectif est de dÃ©velopper un modÃ¨le prÃ©dictif permettant dâ€™identifier les employÃ©s susceptibles de quitter lâ€™entreprise afin de :

- anticiper les dÃ©parts,

- favoriser des actions RH ciblÃ©es,

- amÃ©liorer la rÃ©tention.

# ğŸ—‚ï¸ DonnÃ©es utilisÃ©es

Le projet exploite deux sources principales :

## 1. Base RH gÃ©nÃ©rale

Comprend notamment :

- Age, Gender, Education, Department, JobRole

- DistanceFromHome

- MonthlyIncome, PercentSalaryHike

- TotalWorkingYears, YearsAtCompany

- WorkLifeBalance, JobSatisfaction...

- Attrition (variable cible)

## 2. DerniÃ¨re Ã©valuation managÃ©riale

- EmployeeID

- JobInvolvement

- PerformanceRating

## 3. EnquÃªte sur la qualitÃ© du travail

- EnvironmentSatisfaction

- RelationshipSatisfaction

- WorkLifeBalance

JobSatisfaction

# ğŸ§¹ PrÃ©paration des donnÃ©es

Le notebook inclut :
- Nettoyage des valeurs manquantes
- Encodage des variables catÃ©gorielles
- Analyse exploratoire (corrÃ©lations, distributions, mÃ©triques RH)
- Fusion des diffÃ©rentes sources de donnÃ©es
- Gestion des dÃ©sÃ©quilibres de classes (turnover = 16%)

# ğŸ“Š Analyse exploratoire (EDA)

Les points clÃ©s identifiÃ©s :

- Les employÃ©s jeunes, peu expÃ©rimentÃ©s ou habitant loin ont plus tendance Ã  partir.

- Les scores faibles de satisfaction et de balance vie pro / vie perso sont corrÃ©lÃ©s Ã  lâ€™attrition.

- Le salaire nâ€™est pas un facteur dÃ©terminant isolÃ©.

- Certaines features sont trÃ¨s discriminantes : OverTime, JobRole, EnvironmentSatisfaction, YearsAtCompany.

# ğŸ¤– ModÃ©lisation

Plusieurs modÃ¨les ont Ã©tÃ© testÃ©s dans le notebook :

- Logistic Regression

- Random Forest

- XGBoost

- Decision Tree

- KNN

- SVM

Chaque modÃ¨le a Ã©tÃ© Ã©valuÃ© via :

- Accuracy

- F1-score

- Recall (critique pour ne pas manquer les employÃ©s Ã  risque)

- Matrice de confusion

# ğŸ† RÃ©sultats

Le XGBoost et la Random Forest se distinguent grÃ¢ce Ã  :

- Un bon compromis Recall / PrÃ©cision

- Une forte capacitÃ© Ã  capturer les non-linÃ©aritÃ©s

- Une meilleure gestion du dÃ©sÃ©quilibre de classes

Les variables les plus importantes selon les modÃ¨les :

- OverTime

- JobSatisfaction

- EnvironmentSatisfaction

- TotalWorkingYears

- YearsAtCompany

- WorkLifeBalance

# ğŸ“ˆ Visualisations incluses dans le notebook

- Histogrammes, boxplots, heatmaps

- Analyse des distributions par Ã©tiquette (Attrition vs Non-Attrition)

- Importance des variables

- Matrices de confusion

- Courbes ROC

# ğŸ“¦ Technologies et librairies

- Python 3.x

- pandas, numpy

- matplotlib, seaborn

- scikit-learn

- xgboost

- imbalanced-learn

# ğŸš€ AmÃ©liorations possibles

- Optimisation hyperparamÃ¨tres (GridSearchCV / Optuna)

- IntÃ©gration dâ€™un tableau de bord (Streamlit)

- CrÃ©ation dâ€™un pipeline dÃ©ployable

- Analyse coÃ»t-bÃ©nÃ©fice RH (fausses alertes vs. dÃ©parts manquÃ©s)
